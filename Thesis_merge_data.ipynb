{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn import neighbors, datasets\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speed_total_mean</th>\n",
       "      <th>steering_total_mean</th>\n",
       "      <th>brake_total_mean</th>\n",
       "      <th>throttle_total_mean</th>\n",
       "      <th>acceleration_total_mean</th>\n",
       "      <th>speed_total_var</th>\n",
       "      <th>steering_total_var</th>\n",
       "      <th>brake_total_var</th>\n",
       "      <th>throttle_total_var</th>\n",
       "      <th>acceleration_total_var</th>\n",
       "      <th>total_time</th>\n",
       "      <th>distancePed</th>\n",
       "      <th>max_speed</th>\n",
       "      <th>hadCollision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.919151</td>\n",
       "      <td>0.503649</td>\n",
       "      <td>0.965743</td>\n",
       "      <td>0.820576</td>\n",
       "      <td>0.030731</td>\n",
       "      <td>13.796202</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.014468</td>\n",
       "      <td>0.028719</td>\n",
       "      <td>0.039370</td>\n",
       "      <td>15.405173</td>\n",
       "      <td>89.992450</td>\n",
       "      <td>11.669766</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.580378</td>\n",
       "      <td>0.499771</td>\n",
       "      <td>0.891302</td>\n",
       "      <td>0.878839</td>\n",
       "      <td>-0.026652</td>\n",
       "      <td>31.451253</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.058767</td>\n",
       "      <td>0.010391</td>\n",
       "      <td>0.063480</td>\n",
       "      <td>11.412381</td>\n",
       "      <td>85.063860</td>\n",
       "      <td>13.499710</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.474048</td>\n",
       "      <td>0.494557</td>\n",
       "      <td>0.952182</td>\n",
       "      <td>0.781126</td>\n",
       "      <td>0.006292</td>\n",
       "      <td>53.873833</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>0.022506</td>\n",
       "      <td>0.045416</td>\n",
       "      <td>0.106281</td>\n",
       "      <td>102.356492</td>\n",
       "      <td>789.212800</td>\n",
       "      <td>25.851397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.398595</td>\n",
       "      <td>0.523305</td>\n",
       "      <td>0.960227</td>\n",
       "      <td>0.858795</td>\n",
       "      <td>0.027363</td>\n",
       "      <td>5.036717</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.018643</td>\n",
       "      <td>0.075860</td>\n",
       "      <td>0.027735</td>\n",
       "      <td>14.315100</td>\n",
       "      <td>47.977978</td>\n",
       "      <td>10.266865</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.669419</td>\n",
       "      <td>0.500661</td>\n",
       "      <td>0.891913</td>\n",
       "      <td>0.522365</td>\n",
       "      <td>0.008028</td>\n",
       "      <td>47.209285</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.055982</td>\n",
       "      <td>0.112551</td>\n",
       "      <td>0.159198</td>\n",
       "      <td>7.505478</td>\n",
       "      <td>88.011610</td>\n",
       "      <td>20.055070</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   speed_total_mean  steering_total_mean  brake_total_mean  \\\n",
       "0          5.919151             0.503649          0.965743   \n",
       "1          7.580378             0.499771          0.891302   \n",
       "2          9.474048             0.494557          0.952182   \n",
       "3          3.398595             0.523305          0.960227   \n",
       "4         11.669419             0.500661          0.891913   \n",
       "\n",
       "   throttle_total_mean  acceleration_total_mean  speed_total_var  \\\n",
       "0             0.820576                 0.030731        13.796202   \n",
       "1             0.878839                -0.026652        31.451253   \n",
       "2             0.781126                 0.006292        53.873833   \n",
       "3             0.858795                 0.027363         5.036717   \n",
       "4             0.522365                 0.008028        47.209285   \n",
       "\n",
       "   steering_total_var  brake_total_var  throttle_total_var  \\\n",
       "0            0.000655         0.014468            0.028719   \n",
       "1            0.000345         0.058767            0.010391   \n",
       "2            0.001231         0.022506            0.045416   \n",
       "3            0.000101         0.018643            0.075860   \n",
       "4            0.000396         0.055982            0.112551   \n",
       "\n",
       "   acceleration_total_var  total_time  distancePed  max_speed  hadCollision  \n",
       "0                0.039370   15.405173    89.992450  11.669766             0  \n",
       "1                0.063480   11.412381    85.063860  13.499710             0  \n",
       "2                0.106281  102.356492   789.212800  25.851397             1  \n",
       "3                0.027735   14.315100    47.977978  10.266865             0  \n",
       "4                0.159198    7.505478    88.011610  20.055070             0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"mergeData.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of True cases:  61 (9.31%)\n",
      "Number of False cases: 594 (90.69%)\n"
     ]
    }
   ],
   "source": [
    "num_obs = len(df)\n",
    "num_true = len(df.loc[df['hadCollision'] == 1])\n",
    "num_false = len(df.loc[df['hadCollision'] == 0])\n",
    "print(\"Number of True cases:  {0} ({1:2.2f}%)\".format(num_true, (num_true/num_obs) * 100))\n",
    "print(\"Number of False cases: {0} ({1:2.2f}%)\".format(num_false, (num_false/num_obs) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = df.copy()\n",
    "X = data.drop('hadCollision', axis=1) \n",
    "Y = data['hadCollision']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1, stratify=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN classifier (n = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Create KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "# Fit the classifier to the data\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9007633587786259\n",
      "Confusion Matrix\n",
      "[[117   2]\n",
      " [ 11   1]]\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.98      0.95       119\n",
      "          1       0.33      0.08      0.13        12\n",
      "\n",
      "avg / total       0.86      0.90      0.87       131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check accuracy of our model on the test data\n",
    "from sklearn import metrics\n",
    "\n",
    "print(knn.score(X_test, y_test))\n",
    "print(\"Confusion Matrix\")\n",
    "print(\"{0}\".format(metrics.confusion_matrix(y_test, knn.predict(X_test))))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, knn.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baja certeza para casos verdaderos de choque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN classifier (n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Create KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "# Fit the classifier to the data\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9083969465648855\n",
      "Confusion Matrix\n",
      "[[119   0]\n",
      " [ 12   0]]\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95       119\n",
      "          1       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.83      0.91      0.86       131\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(knn.score(X_test, y_test))\n",
    "print(\"Confusion Matrix\")\n",
    "print(\"{0}\".format(metrics.confusion_matrix(y_test, knn.predict(X_test))))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, knn.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nula certeza para casos verdaderos de choque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN with cv score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91666667 0.90839695 0.91603053 0.91603053 0.90769231]\n",
      "cv_scores mean:0.9129633979252301\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "#create a new KNN model\n",
    "knn_cv = KNeighborsClassifier(n_neighbors=3)\n",
    "#train model with cv of 5 \n",
    "cv_scores = cross_val_score(knn_cv, X, Y, cv=5)\n",
    "#print each cv score (accuracy) and average them\n",
    "print(cv_scores)\n",
    "print('cv_scores mean:{}'.format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV n neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#create new a knn model\n",
    "knn2 = KNeighborsClassifier()\n",
    "#create a dictionary of all values we want to test for n_neighbors\n",
    "param_grid = {'n_neighbors': np.arange(1, 25)}\n",
    "#use gridsearch to test all values for n_neighbors\n",
    "knn_gscv = GridSearchCV(knn2, param_grid, cv=5)\n",
    "#fit model to data\n",
    "knn_gscv.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 2}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check top performing n_neighbors value\n",
    "knn_gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.917557251908397"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check mean score for the top performing value of n_neighbors\n",
    "knn_gscv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN classifier (n = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=2, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Create KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 2)\n",
    "# Fit the classifier to the data\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9083969465648855\n",
      "Confusion Matrix\n",
      "[[118   1]\n",
      " [ 11   1]]\n",
      "\n",
      "Classification Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.99      0.95       119\n",
      "          1       0.50      0.08      0.14        12\n",
      "\n",
      "avg / total       0.88      0.91      0.88       131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(knn.score(X_test, y_test))\n",
    "print(\"Confusion Matrix\")\n",
    "print(\"{0}\".format(metrics.confusion_matrix(y_test, knn.predict(X_test))))\n",
    "print(\"\")\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(metrics.classification_report(y_test, knn.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados parecidos a n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
